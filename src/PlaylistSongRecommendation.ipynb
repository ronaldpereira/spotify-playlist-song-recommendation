{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_reader(begin):\n",
    "    if begin not in np.arange(0, 11000, 1000):\n",
    "        raise Exception(\n",
    "            \"Invalid start pid! Start pids must be {0, 1000, 2000, ..., 999000}\"\n",
    "        )\n",
    "\n",
    "    end = begin + 1000\n",
    "    path = \"../data/mpd.slice.\" + str(begin) + \"-\" + str(end - 1) + \".json\"\n",
    "\n",
    "    jsonData = json.load(open(path, \"r\"))\n",
    "    actualSlice = pd.DataFrame.from_dict(jsonData[\"playlists\"], orient=\"columns\")\n",
    "    return actualSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonList = []\n",
    "for begin in np.arange(0, 11000, 1000):\n",
    "    actual = json_reader(begin)\n",
    "    jsonList.append(actual)\n",
    "\n",
    "trainData = pd.concat(jsonList)\n",
    "jsonList.clear()\n",
    "\n",
    "print(trainData.shape)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn playlist level dataframe into song level dataframe\n",
    "# is a df of all track ids, cooresponding artist names, track names and playlist ids\n",
    "\n",
    "songPlaylistArray = []\n",
    "for index, row in trainData.iterrows():\n",
    "    for track in row[\"tracks\"]:\n",
    "        songPlaylistArray.append(\n",
    "            [track[\"track_uri\"], track[\"artist_name\"], track[\"track_name\"], row[\"pid\"]]\n",
    "        )\n",
    "songPlaylist = pd.DataFrame(\n",
    "    songPlaylistArray, columns=[\"trackid\", \"artist_name\", \"track_name\", \"pid\"]\n",
    ")\n",
    "\n",
    "print(songPlaylist.shape)\n",
    "songPlaylist.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn songs into their unqiue cat codes so we have a 0-N index for tracks\n",
    "songPlaylist[\"trackindex\"] = songPlaylist[\"trackid\"].astype(\"category\").cat.codes\n",
    "\n",
    "print(len(songPlaylist[\"trackindex\"].unique()))\n",
    "print(songPlaylist.shape)\n",
    "songPlaylist.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in DOK (Dictionary Of Keys) matrix (optimized sparse matrix object)\n",
    "# Create a sparse pid x trackindex matrix\n",
    "# If a pid i has song j, mat[i,j]=1\n",
    "\n",
    "mat = sp.dok_matrix((11000, 180409), dtype=np.float32)\n",
    "for pid, trackindex in zip(songPlaylist[\"pid\"], songPlaylist[\"trackindex\"]):\n",
    "    mat[pid, trackindex] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.layers.core import Dense, Lambda, Activation\n",
    "from keras.layers import Embedding, Input, Dense, Reshape, multiply, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_playlists, num_items, latent_dim, regs=[0, 0]):\n",
    "    # Input variables\n",
    "    playlist_input = Input(shape=(1,), dtype=\"int32\", name=\"playlist_input\")\n",
    "\n",
    "    item_input = Input(shape=(1,), dtype=\"int32\", name=\"item_input\")\n",
    "\n",
    "    playlist_embedding = Embedding(\n",
    "        name=\"playlist_embedding\",\n",
    "        input_dim=num_playlists,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_regularizer=l2(regs[0]),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    item_embedding = Embedding(\n",
    "        name=\"item_embedding\",\n",
    "        input_dim=num_items,\n",
    "        output_dim=latent_dim,\n",
    "        embeddings_regularizer=l2(regs[1]),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    # Flattens the embedding vector\n",
    "    playlist_latent = Flatten()(playlist_embedding(playlist_input))\n",
    "    item_latent = Flatten()(item_embedding(item_input))\n",
    "\n",
    "    # Element-wise product of playlist and item embeddings\n",
    "    predict_vector = multiply([playlist_latent, item_latent])\n",
    "\n",
    "    # Final prediction layer\n",
    "    prediction = Dense(\n",
    "        1,\n",
    "        activation=\"sigmoid\",\n",
    "        kernel_initializer=\"random_normal\",\n",
    "        name=\"prediction_layer\",\n",
    "    )(predict_vector)\n",
    "\n",
    "    model = Model(inputs=[playlist_input, item_input], outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives):\n",
    "    playlist_input, item_input, labels = [], [], []\n",
    "    num_playlists = train.shape[0]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instances\n",
    "        playlist_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for t in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while (u, j) in train:\n",
    "                j = np.random.randint(num_items)\n",
    "            playlist_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "\n",
    "    return playlist_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters\n",
    "num_factors = 8\n",
    "regs = [0, 0]\n",
    "num_negatives = 4\n",
    "learning_rate = 0.01\n",
    "epochs = 15\n",
    "batch_size = 500\n",
    "\n",
    "# Loading data\n",
    "train = mat\n",
    "num_playlists, num_items = train.shape\n",
    "\n",
    "# Build and compile model\n",
    "model = get_model(num_playlists, num_items, num_factors, regs)\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=learning_rate), loss=\"binary_crossentropy\", metrics=[\"acc\"]\n",
    ")\n",
    "print(model.summary())\n",
    "\n",
    "# Train model\n",
    "# Generate training instances\n",
    "playlist_input, item_input, labels = get_train_instances(train, num_negatives)\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    [np.array(playlist_input), np.array(item_input)],  # input\n",
    "    np.array(labels),  # labels\n",
    "    validation_split=0.2,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
